{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd30c9ef",
   "metadata": {},
   "source": [
    "# Introduction to MPI on Amazon SageMaker\n",
    "\n",
    "Message Passing Interface (MPI) is the fundamental communication protocol for programming parallel computer programs. See its [wiki page](https://en.wikipedia.org/wiki/Message_Passing_Interface). [Open MPI](https://www.open-mpi.org/projects/user-docs/) is the implementation that's used as a basic building block for distributed training systems. \n",
    "\n",
    "In Python programs, you can interact with Open MPI APIs via [mpi4py](https://mpi4py.readthedocs.io/en/stable/overview.html) and easily convert your single-process python program into a parallel python program. \n",
    "\n",
    "Parallel processes can exist on one host (e.g. one EC2 instance) or multiple hosts (e.g. many EC2 instances). It's trivial to set up a parallel cluster (comm world, in MPI parlance) on one host via Open MPI, but it is less straight-forward to set up an MPI comm world across multiple instances. \n",
    "\n",
    "SageMaker does it for you. In this tutorial, you will go through a few basic (but exceeding important) [MPI communications](https://mpi4py.readthedocs.io/en/stable/tutorial.html) on SageMaker with **multiple instances** and you will verify that parallel processes across instances are indeed talking to each other. Those basic communications are the fundamental building blocks for distributed training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d4b20a",
   "metadata": {},
   "source": [
    "## Environment \n",
    "We assume Open MPI and mpi4py have been installed in your environment. This is the case for SageMaker Notebook Instance or Studio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb2c14",
   "metadata": {},
   "source": [
    "## Inspect the Python Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c476b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmpi4py\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m MPI\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "size = comm.Get_size()\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m rank == \u001b[34m0\u001b[39;49;00m:\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mNumber of MPI processes that will talk to each other:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, size)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpoint_to_point\u001b[39;49;00m():\n",
      "    \u001b[33m\"\"\"Point to point communication\u001b[39;49;00m\n",
      "\u001b[33m    Send a numpy array (buffer like object) from rank 0 to rank 1\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m rank == \u001b[34m0\u001b[39;49;00m:\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mpoint to point\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        data = np.array([\u001b[34m0\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m], dtype=np.intc)  \u001b[37m# int in C\u001b[39;49;00m\n",
      "\n",
      "        \u001b[37m# remember the difference between\u001b[39;49;00m\n",
      "        \u001b[37m# Upper case API and lower case API\u001b[39;49;00m\n",
      "        \u001b[37m# Basically uppper case API directly calls C API\u001b[39;49;00m\n",
      "        \u001b[37m# so it is fast\u001b[39;49;00m\n",
      "        \u001b[37m# checkout https://mpi4py.readthedocs.io/en/stable/\u001b[39;49;00m\n",
      "\n",
      "        comm.Send([data, MPI.INT], dest=\u001b[34m1\u001b[39;49;00m)\n",
      "    \u001b[34melif\u001b[39;49;00m rank == \u001b[34m1\u001b[39;49;00m:\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mHello I am rank \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrank\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        data = np.empty(\u001b[34m3\u001b[39;49;00m, dtype=np.intc)\n",
      "        comm.Recv([data, MPI.INT], source=\u001b[34m0\u001b[39;49;00m)\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mI received some data:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, data)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m rank == \u001b[34m0\u001b[39;49;00m:\n",
      "        time.sleep(\u001b[34m1\u001b[39;49;00m)  \u001b[37m# give some buffer time for execution to complete\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m=\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m * \u001b[34m50\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mbroadcast\u001b[39;49;00m():\n",
      "    \u001b[33m\"\"\"Broadcast a numpy array from rank 0 to others\"\"\"\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m rank == \u001b[34m0\u001b[39;49;00m:\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mBroadcasting from rank \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrank\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        data = np.arange(\u001b[34m10\u001b[39;49;00m, dtype=np.intc)\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        data = np.empty(\u001b[34m10\u001b[39;49;00m, dtype=np.intc)\n",
      "\n",
      "    comm.Bcast([data, MPI.INT], root=\u001b[34m0\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mData at rank \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrank\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, data)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m rank == \u001b[34m0\u001b[39;49;00m:\n",
      "        time.sleep(\u001b[34m1\u001b[39;49;00m)\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m=\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m * \u001b[34m50\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mgather_reduce_broadcast\u001b[39;49;00m():\n",
      "    \u001b[33m\"\"\"Gather numpy arrays from all ranks to rank 0\u001b[39;49;00m\n",
      "\u001b[33m    then take average and broadcast result to other ranks\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    It is a useful operation in distributed training:\u001b[39;49;00m\n",
      "\u001b[33m    train a model in a few MPI workers with different\u001b[39;49;00m\n",
      "\u001b[33m    input data, then take average weights on rank 0 and\u001b[39;49;00m\n",
      "\u001b[33m    synchroinze weights on other ranks\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m# stuff to gather at each rank\u001b[39;49;00m\n",
      "    sendbuf = np.zeros(\u001b[34m10\u001b[39;49;00m, dtype=np.intc) + rank\n",
      "    recvbuf = \u001b[34mNone\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m rank == \u001b[34m0\u001b[39;49;00m:\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGather and reduce\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        recvbuf = np.empty([size, \u001b[34m10\u001b[39;49;00m], dtype=np.intc)\n",
      "    comm.Gather(sendbuf, recvbuf, root=\u001b[34m0\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m rank == \u001b[34m0\u001b[39;49;00m:\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mI am rank \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrank\u001b[33m}\u001b[39;49;00m\u001b[33m, data I gathered is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrecvbuf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "        \u001b[37m# take average\u001b[39;49;00m\n",
      "        \u001b[37m# think of it as a prototype of\u001b[39;49;00m\n",
      "        \u001b[37m# average weights, average gradients etc\u001b[39;49;00m\n",
      "        avg = np.mean(recvbuf, axis=\u001b[34m0\u001b[39;49;00m, dtype=np.float)\n",
      "\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[37m# get averaged array from rank 0\u001b[39;49;00m\n",
      "        \u001b[37m# think of it as a prototype of\u001b[39;49;00m\n",
      "        \u001b[37m# synchronizing weights across different MPI procs\u001b[39;49;00m\n",
      "        avg = np.empty(\u001b[34m10\u001b[39;49;00m, dtype=np.float)\n",
      "\n",
      "    \u001b[37m# Note that the data type is float here\u001b[39;49;00m\n",
      "    \u001b[37m# because we took average\u001b[39;49;00m\n",
      "    comm.Bcast([avg, MPI.FLOAT], root=\u001b[34m0\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mI am rank \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrank\u001b[33m}\u001b[39;49;00m\u001b[33m, my avg is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mavg\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    point_to_point()\n",
      "    broadcast()\n",
      "    gather_reduce_broadcast()\n"
     ]
    }
   ],
   "source": [
    "!pygmentize mpi_demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe4ed9",
   "metadata": {},
   "source": [
    "See the program in action with 2 parallel processes on your current environment. Make sure you have at least 2 cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "142d9094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello I am rank 1\n",
      "Number of MPI processes that will talk to each other: 2\n",
      "point to point\n",
      "I received some data: [0 1 2]\n",
      "==================================================\n",
      "Broadcasting from rank 0\n",
      "Data at rank 0 [0 1 2 3 4 5 6 7 8 9]\n",
      "Data at rank 1 [0 1 2 3 4 5 6 7 8 9]\n",
      "==================================================\n",
      "Gather and reduce\n",
      "I am rank 0, data I gathered is: [[0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]]\n",
      "I am rank 0, my avg is: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "I am rank 1, my avg is: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "mpi_demo.py:83: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  avg = np.mean(recvbuf, axis=0, dtype=np.float)\n",
      "mpi_demo.py:89: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  avg = np.empty(10, dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 2 python mpi_demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32930f",
   "metadata": {},
   "source": [
    "## Scale it on SageMaker\n",
    "You can run the above program with $n$ processes per host across $N$ hosts on SageMaker (and get a comm world of size $n\\times N$). In the remaining of this notebook, you will use SageMaker TensorFlow deep learning container to run the above program. There is no particular reason for the choice, all SageMaker deep learning containers have Open MPI installed. So feel free to replace it with your favorite DLC. \n",
    "\n",
    "Check out the [SageMaker Python SDK Docs](https://sagemaker.readthedocs.io/en/stable/api/training/smd_model_parallel_general.html?highlight=mpi%20paramters#mpi-parameters) for the parameters needed to set up a distributed training job with MPI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677ace6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "#role = get_execution_role()\n",
    "role = 'arn:aws:iam::976939723775:role/service-role/AmazonSageMaker-ExecutionRole-20210317T133000'\n",
    "# Running 2 processes per host\n",
    "# if we use 3 instances,\n",
    "# then we should see 6 MPI processes\n",
    "\n",
    "distribution = {\"mpi\": {\"enabled\": True, \"processes_per_host\": 2}}\n",
    "\n",
    "tfest = TensorFlow(\n",
    "    entry_point=\"mpi_demo.py\",\n",
    "    role=role,\n",
    "    framework_version=\"2.3.0\",\n",
    "    distribution=distribution,\n",
    "    py_version=\"py37\",\n",
    "    instance_count=3,\n",
    "    instance_type=\"ml.c5.2xlarge\",  # 8 cores\n",
    "    output_path=\"s3://\" + sagemaker.Session().default_bucket() + \"/\" + \"tf_mpi\",\n",
    ")\n",
    "\n",
    "torchfest = PyTorch(\n",
    "    entry_point=\"mpi_demo.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.10.0\",\n",
    "    distribution=distribution,\n",
    "    py_version=\"py38\",\n",
    "    instance_count=3,\n",
    "    instance_type=\"ml.c5.2xlarge\",  # 8 cores\n",
    "    output_path=\"s3://\" + sagemaker.Session().default_bucket() + \"/\" + \"torch_mpi\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b19a91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 17:54:31 Starting - Starting the training job...\n",
      "2022-07-06 17:54:56 Starting - Preparing the instances for trainingProfilerReport-1657130070: InProgress\n",
      ".........\n",
      "2022-07-06 17:56:26 Downloading - Downloading input data\n",
      "2022-07-06 17:56:26 Training - Downloading the training image...\n",
      "2022-07-06 17:56:56 Training - Training image download completed. Training in progress..\u001b[32m2022-07-06 17:57:00,835 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:00,842 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:01,206 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:01,221 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:01,229 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:01,229 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:01,231 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:01,231 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.74.200\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:01,467 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:01,474 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:01,887 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:01,904 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:01,913 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:01,913 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:01,922 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:01,923 sagemaker-training-toolkit INFO     Cannot connect to host algo-2\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:01,923 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.66.255\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:02,238 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:02,304 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:02,304 sagemaker-training-toolkit INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:02,304 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:02,304 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:02,313 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:02,929 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:02,995 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:02,995 sagemaker-training-toolkit INFO     Can connect to host algo-2\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:02,995 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:03,001 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:03,064 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:03,064 sagemaker-training-toolkit INFO     Can connect to host algo-3\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:03,064 sagemaker-training-toolkit INFO     Worker algo-3 available for communication\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:03,064 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1', 'algo-2', 'algo-3'] Hosts: ['algo-1:2', 'algo-2:2', 'algo-3:2'] process_per_hosts: 2 num_processes: 6\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:03,065 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:03,074 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:03,083 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_mpi_enabled\": true,\n",
      "        \"sagemaker_mpi_num_of_processes_per_host\": 2\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"/opt/ml/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2022-07-06-17-54-30-735\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-976939723775/tensorflow-training-2022-07-06-17-54-30-735/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mpi_demo\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-3\",\n",
      "                    \"algo-2\",\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mpi_demo.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"/opt/ml/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mpi_demo.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":2}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mpi_demo\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-976939723775/tensorflow-training-2022-07-06-17-54-30-735/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":2},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"model_dir\":\"/opt/ml/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2022-07-06-17-54-30-735\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-976939723775/tensorflow-training-2022-07-06-17-54-30-735/source/sourcedir.tar.gz\",\"module_name\":\"mpi_demo\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mpi_demo.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"/opt/ml/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:2,algo-2:2,algo-3:2 -np 6 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/usr/local/lib/python3.7/site-packages/gethostname.cpython-37m-x86_64-linux-gnu.so -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_HP_MODEL_DIR -x PYTHONPATH /usr/local/bin/python3.7 -m mpi4py mpi_demo.py --model_dir /opt/ml/model\n",
      " Data for JOB [17774,1] offset 0 Total slots allocated 6\n",
      " ========================   JOB MAP   ========================\n",
      " Data for node: ip-10-0-74-200#011Num slots: 2#011Max slots: 0#011Num procs: 2\n",
      " #011Process OMPI jobid: [17774,1] App: 0 Process rank: 0 Bound: N/A\n",
      " #011Process OMPI jobid: [17774,1] App: 0 Process rank: 1 Bound: N/A\n",
      " Data for node: algo-2#011Num slots: 2#011Max slots: 0#011Num procs: 2\n",
      " #011Process OMPI jobid: [17774,1] App: 0 Process rank: 2 Bound: N/A\n",
      " #011Process OMPI jobid: [17774,1] App: 0 Process rank: 3 Bound: N/A\n",
      " Data for node: algo-3#011Num slots: 2#011Max slots: 0#011Num procs: 2\n",
      " #011Process OMPI jobid: [17774,1] App: 0 Process rank: 4 Bound: N/A\n",
      " #011Process OMPI jobid: [17774,1] App: 0 Process rank: 5 Bound: N/A\n",
      " =============================================================\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Hello I am rank 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Number of MPI processes that will talk to each other: 6\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:point to point\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:I received some data: [1,1]<stdout>:[0 1 2]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:==================================================\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Broadcasting from rank 0\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Data at rank 5 [1,5]<stdout>:[0 1 2 3 4 5 6 7 8 9]\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Data at rank 4 [1,4]<stdout>:[0 1 2 3 4 5 6 7 8 9]\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Data at rank 1 [1,1]<stdout>:[0 1 2 3 4 5 6 7 8 9]\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Data at rank 3 [1,3]<stdout>:[0 1 2 3 4 5 6 7 8 9]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Data at rank 0 [1,2]<stdout>:Data at rank 2 [1,0]<stdout>:[0 1 2 3 4 5 6 7 8 9]\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[0 1 2 3 4 5 6 7 8 9]\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:01,079 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:01,085 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:01,480 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:01,494 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:01,503 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:01,503 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:01,504 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:01,504 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.74.200\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:02,510 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:02,603 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:02,603 sagemaker-training-toolkit INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:02,603 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:02,603 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:02,613 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:==================================================\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Gather and reduce\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:I am rank 0, data I gathered is: [[0 0 0 0 0 0 0 0 0 0]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [1 1 1 1 1 1 1 1 1 1]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [2 2 2 2 2 2 2 2 2 2]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [3 3 3 3 3 3 3 3 3 3]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [4 4 4 4 4 4 4 4 4 4]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: [5 5 5 5 5 5 5 5 5 5]]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:I am rank 0, my avg is: [2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5]\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:I am rank 1, my avg is: [2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5]\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:I am rank 3, my avg is: [2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5]\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:I am rank 2, my avg is: [2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5]\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:I am rank 5, my avg is: [2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5]\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:I am rank 4, my avg is: [2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5]\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:05,808 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[34mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[34mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[34m2022-07-06 17:57:05,809 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:35,849 sagemaker-training-toolkit INFO     MPI process finished.\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:35,849 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[35mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[35mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[35m2022-07-06 17:57:35,849 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:35,850 sagemaker-training-toolkit INFO     MPI process finished.\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:35,850 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[32mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[32mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[32m2022-07-06 17:57:35,850 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-07-06 17:57:53 Uploading - Uploading generated training model\n",
      "2022-07-06 17:57:53 Completed - Training job completed\n",
      "Training seconds: 291\n",
      "Billable seconds: 291\n"
     ]
    }
   ],
   "source": [
    "tfest.fit(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb2461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 18:50:57 Starting - Starting the training job."
     ]
    }
   ],
   "source": [
    "torchfest.fit(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dadd21",
   "metadata": {},
   "source": [
    "The stdout \"Number of MPI processes that will talk to each other:  6\" indicates that the processes on all hosts are included in the comm world. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762a703",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, you went through some fundamental MPI operations, which are the bare bones of inner workings of many distributed training frameworks. You did that on SageMaker with multiple instances. You can scale up this set up to include more instances in a real ML project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
