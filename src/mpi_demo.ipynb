{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a76c62",
   "metadata": {},
   "source": [
    "# Introduction to MPI on Amazon SageMaker\n",
    "\n",
    "Message Passing Interface (MPI) is the fundamental communication protocol for programming parallel computer programs. See its [wiki page](https://en.wikipedia.org/wiki/Message_Passing_Interface). [Open MPI](https://www.open-mpi.org/projects/user-docs/) is the implementation that's used as a basic building block for distributed training systems. \n",
    "\n",
    "In Python programs, you can interact with Open MPI APIs via [mpi4py](https://mpi4py.readthedocs.io/en/stable/overview.html) and easily convert your single-process python program into a parallel python program. \n",
    "\n",
    "Parallel processes can exist on one host (e.g. one EC2 instance) or multiple hosts (e.g. many EC2 instances). It's trivial to set up a parallel cluster (comm world, in MPI parlance) on one host via Open MPI, but it is less straight-forward to set up an MPI comm world across multiple instances. \n",
    "\n",
    "SageMaker does it for you. In this tutorial, you will go through a few basic (but exceeding important) [MPI communications](https://mpi4py.readthedocs.io/en/stable/tutorial.html) on SageMaker with **multiple instances** and you will verify that parallel processes across instances are indeed talking to each other. Those basic communications are the fundamental building blocks for distributed training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f2ba8",
   "metadata": {},
   "source": [
    "## Environment \n",
    "We assume Open MPI and mpi4py have been installed in your environment. This is the case for SageMaker Notebook Instance or Studio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819f590a",
   "metadata": {},
   "source": [
    "## Inspect the Python Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c86fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize mpi_demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6948c2",
   "metadata": {},
   "source": [
    "See the program in action with 2 parallel processes on your current environment. Make sure you have at least 2 cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b79f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun -np 2 python mpi_demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f6708c",
   "metadata": {},
   "source": [
    "## Scale it on SageMaker\n",
    "You can run the above program with $n$ processes per host across $N$ hosts on SageMaker (and get a comm world of size $n\\times N$). In the remaining of this notebook, you will use SageMaker TensorFlow deep learning container to run the above program. There is no particular reason for the choice, all SageMaker deep learning containers have Open MPI installed. So feel free to replace it with your favorite DLC. \n",
    "\n",
    "Check out the [SageMaker Python SDK Docs](https://sagemaker.readthedocs.io/en/stable/api/training/smd_model_parallel_general.html?highlight=mpi%20paramters#mpi-parameters) for the parameters needed to set up a distributed training job with MPI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b55a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "#role = get_execution_role()\n",
    "role = 'arn:aws:iam::976939723775:role/service-role/AmazonSageMaker-ExecutionRole-20210317T133000'\n",
    "# Running 2 processes per host\n",
    "# if we use 3 instances,\n",
    "# then we should see 6 MPI processes\n",
    "\n",
    "distribution = {\"mpi\": {\"enabled\": True, \"processes_per_host\": 2}}\n",
    "\n",
    "tfest = TensorFlow(\n",
    "    entry_point=\"mpi_demo.py\",\n",
    "    role=role,\n",
    "    framework_version=\"2.3.0\",\n",
    "    distribution=distribution,\n",
    "    py_version=\"py37\",\n",
    "    instance_count=3,\n",
    "    instance_type=\"ml.c5.2xlarge\",  # 8 cores\n",
    "    output_path=\"s3://\" + sagemaker.Session().default_bucket() + \"/\" + \"tf_mpi\",\n",
    ")\n",
    "\n",
    "torchfest = PyTorch(\n",
    "    entry_point=\"mpi_demo.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.10.0\",\n",
    "    distribution=distribution,\n",
    "    py_version=\"py38\",\n",
    "    instance_count=3,\n",
    "    instance_type=\"ml.c5.2xlarge\",  # 8 cores\n",
    "    output_path=\"s3://\" + sagemaker.Session().default_bucket() + \"/\" + \"torch_mpi\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d20b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfest.fit(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688415ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchfest.fit(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bc2b1c",
   "metadata": {},
   "source": [
    "The stdout \"Number of MPI processes that will talk to each other:  6\" indicates that the processes on all hosts are included in the comm world. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ea5c3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, you went through some fundamental MPI operations, which are the bare bones of inner workings of many distributed training frameworks. You did that on SageMaker with multiple instances. You can scale up this set up to include more instances in a real ML project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
